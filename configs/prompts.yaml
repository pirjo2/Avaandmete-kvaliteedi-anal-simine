meta:
  name: Vetr√≤ open data quality symbol prompts (variant B)
  version: "0.2-B"
  style: "three-line explicit answers"
  notes:
    - All answers MUST be in exactly three lines, in this order:
    - "answer: <value>"
    - "confidence: <number between 0 and 1>"
    - "evidence: <short free-text explanation>"

symbols:
  c:
    type: binary
    description: "Does the dataset have a high-level category / theme field in its metadata?"
    prompt: |
      You help assess open data quality.
      Question: Based on the context, is it reasonable to assume that the dataset has a CATEGORY or THEME field in its portal metadata (for example, health, transport, environment)?
      Treat this as present if it is an official statistical or government dataset that would normally be categorised.
      Answer STRICTLY in three lines:
      answer: 1 if category/theme metadata is clearly present or safely inferable, otherwise 0
      confidence: a number between 0 and 1 (use higher values only if the evidence is strong)
      evidence: a short justification mentioning the clues you used

  t:
    type: binary
    description: "Is there a clear human-readable title for the dataset?"
    prompt: |
      You help assess open data quality.
      Question: Does the dataset have a clear, human-readable TITLE (for example, 'Influenza vaccinations by location and age group')?
      Assume that if you can write a precise title from the context, then title metadata exists.
      Answer STRICTLY in three lines:
      answer: 1 if a clear title is present or clearly inferable, otherwise 0
      confidence: a number between 0 and 1
      evidence: a short justification mentioning the clues you used

  d:
    type: binary
    description: "Is there a description text explaining the dataset contents?"
    prompt: |
      You help assess open data quality.
      Question: Is there a DESCRIPTION field explaining what the dataset contains and how to interpret it?
      If the context is rich enough that a portal would normally include a paragraph of description, you may answer 1.
      Answer STRICTLY in three lines:
      answer: 1 if a description is likely present, otherwise 0
      confidence: a number between 0 and 1
      evidence: a short justification mentioning the clues you used

  id:
    type: binary
    description: "Is there a stable identifier for the dataset in the portal metadata?"
    prompt: |
      You help assess open data quality.
      Question: Does the dataset have a STABLE IDENTIFIER in its portal (for example, a UUID, short code, or permanent slug)?
      If any permanent identifier is visible or strongly implied, treat this as present.
      Answer STRICTLY in three lines:
      answer: 1 if a stable identifier exists or is strongly implied, otherwise 0
      confidence: a number between 0 and 1
      evidence: a short justification mentioning the clues you used

  pb:
    type: binary
    description: "Is the publisher/maintainer of the dataset clearly identified?"
    prompt: |
      You help assess open data quality.
      Question: Is it clear which ORGANISATION publishes or maintains the dataset (for example, a ministry or statistical office)?
      Consider health, statistics or government agencies as plausible publishers when the context strongly suggests them.
      Answer STRICTLY in three lines:
      answer: 1 if the publisher is explicitly mentioned or very clearly inferable, otherwise 0
      confidence: a number between 0 and 1
      evidence: a short justification mentioning the clues you used

  cv:
    type: binary
    description: "Is there clear coverage metadata (geographical, temporal or population)?"
    prompt: |
      You help assess open data quality.
      Question: Does the dataset metadata clearly indicate coverage, such as country, region, time period or population group?
      If the context explicitly lists geography, dates or population groups, you may answer 1.
      Answer STRICTLY in three lines:
      answer: 1 if coverage metadata is clearly present or strongly implied, otherwise 0
      confidence: a number between 0 and 1
      evidence: a short justification mentioning the clues you used

  l:
    type: binary
    description: "Is the language of the dataset and metadata clearly indicated?"
    prompt: |
      You help assess open data quality.
      Question: Is the LANGUAGE of the dataset and its metadata clear (for example, English or Estonian)?
      If all column names and terms are clearly in a single language, treat this as present.
      Answer STRICTLY in three lines:
      answer: 1 if the language is obvious or explicitly stated, otherwise 0
      confidence: a number between 0 and 1
      evidence: a short justification mentioning the clues you used
