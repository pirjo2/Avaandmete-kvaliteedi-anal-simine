meta:
  name: "VetrÃ² symbol prompting pack (heuristic)"
  version: "2.1"
  notes:
    - "Heuristic mode: if explicit metadata is missing, infer from column names, sample values and common open-data patterns."
    - "Strict parsing: answer + confidence + evidence on separate lines."
    - "Optional placeholders: {dataset_description}, {columns}, {profile}, {file_ext}, {N}."
    - "Expected outputs: binary -> 0/1; count_0_to_N -> integer 0..N; date -> YYYY-MM-DD or UNKNOWN."

symbols:
  s:
    type: binary
    prompt: |
      Task: Open data metadata check (heuristic).
      Question: Is the DATA SOURCE stated or reasonably inferable (publisher org/system/source system)?
      Explicit: publisher organisation/system name or source system.
      Heuristic: column names/values clearly imply an official source (e.g., Statistics Estonia, ministry/agency names, official codes).

      Return EXACTLY 3 lines:
      answer: 1 or 0
      confidence: 0.0 to 1.0
      evidence: quote OR "inferred from <reason>" OR "none"
      Rules: Do NOT answer Yes/No. No extra text.

  dc:
    type: binary
    prompt: |
      Task: Metadata check (heuristic).
      Question: Is a CREATION/ISSUED DATE present or strongly implied?
      Explicit: "created/issued" date in metadata.
      Heuristic: presence of a clear creation timestamp column (CreatedAt/IssuedAt) or similar.

      Return EXACTLY 3 lines:
      answer: 1 or 0
      confidence: 0.0 to 1.0
      evidence: quote OR inferred-from-column OR none
      Rules: Do NOT answer Yes/No. No extra text.

  lu:
    type: binary
    prompt: |
      Task: Metadata check (heuristic).
      Question: Is an update log / version history present or inferable?
      Explicit: changelog, versions list, release notes.
      Heuristic: columns like Version, Revision, ChangeLog, or multiple dated versions.

      Return EXACTLY 3 lines:
      answer: 1 or 0
      confidence: 0.0 to 1.0
      evidence: quote OR inferred-from-column OR none
      Rules: Do NOT answer Yes/No. No extra text.

  du:
    type: binary
    prompt: |
      Task: Metadata check (heuristic).
      Question: Are update DATES mentioned or inferable?
      Explicit: "last updated", dated versions, update timestamps.
      Heuristic: columns like ModifiedAt/UpdatedAt/LastModified with timestamps.

      Return EXACTLY 3 lines:
      answer: 1 or 0
      confidence: 0.0 to 1.0
      evidence: quote OR inferred-from-column OR none
      Rules: Do NOT answer Yes/No. No extra text.

  dp:
    type: date
    prompt: |
      Task: Date extraction (heuristic).
      Question: What is the dataset PUBLICATION date or LAST UPDATED date?
      Prefer explicit metadata. If missing, infer from ModifiedAt/UpdatedAt columns (use most recent date).
      If no reasonable date exists, return UNKNOWN.

      Return EXACTLY 3 lines:
      answer: YYYY-MM-DD or UNKNOWN
      confidence: 0.0 to 1.0
      evidence: quote OR inferred-from-column OR none
      Rules: Do NOT output the literal placeholder "YYYY-MM-DD". No extra text.

  sd:
    type: date
    prompt: |
      Task: Date extraction (heuristic).
      Question: What is the START date of the time period referred by the dataset?
      Prefer explicit metadata. If missing, infer from the earliest date-like column (min date).
      If no reasonable date exists, return UNKNOWN.

      Return EXACTLY 3 lines:
      answer: YYYY-MM-DD or UNKNOWN
      confidence: 0.0 to 1.0
      evidence: quote OR inferred-from-column OR none
      Rules: Do NOT output the literal placeholder "YYYY-MM-DD". No extra text.

  edp:
    type: date
    prompt: |
      Task: Date extraction (heuristic).
      Question: What is the END date of the time period referred by the dataset?
      Prefer explicit metadata. If missing, infer from the latest date-like column (max date).
      If no reasonable date exists, return UNKNOWN.

      Return EXACTLY 3 lines:
      answer: YYYY-MM-DD or UNKNOWN
      confidence: 0.0 to 1.0
      evidence: quote OR inferred-from-column OR none
      Rules: Do NOT output the literal placeholder "YYYY-MM-DD". No extra text.

  ed:
    type: date
    prompt: |
      Task: Date extraction (heuristic).
      Question: What is the EXPIRATION date of the previous dataset version (when the previous version became outdated)?
      If not explicit, you may infer expiration as the end date of the previous period ONLY if clearly implied.
      Otherwise return UNKNOWN.

      Return EXACTLY 3 lines:
      answer: YYYY-MM-DD or UNKNOWN
      confidence: 0.0 to 1.0
      evidence: quote OR inferred-from-reason OR none
      Rules: Do NOT output the literal placeholder "YYYY-MM-DD". No extra text.

  c:
    type: binary
    prompt: |
      Task: eGMS/Dublin Core presence (heuristic).
      Field: Category/Subject/Theme.
      Question: Is a category/theme present OR inferable from dataset description/column names?
      Heuristic: obvious topic columns like "Vaccination", "Budget", "Transport", etc.

      Return EXACTLY 3 lines:
      answer: 1 or 0
      confidence: 0.0 to 1.0
      evidence: quote OR inferred-from-topic OR none
      Rules: Do NOT answer Yes/No. No extra text.

  t:
    type: binary
    prompt: |
      Task: eGMS/Dublin Core presence (heuristic).
      Field: Title.
      Question: Is a title present OR inferable as a clear dataset name/topic in the context?
      Heuristic: if context includes a dataset name or file name, treat as inferred title.

      Return EXACTLY 3 lines:
      answer: 1 or 0
      confidence: 0.0 to 1.0
      evidence: quote OR inferred-from-name OR none
      Rules: Do NOT answer Yes/No. No extra text.

  d:
    type: binary
    prompt: |
      Task: eGMS/Dublin Core presence (heuristic).
      Field: Description.
      Question: Is a human-readable DESCRIPTION present OR inferable (context explains what the data represents)?
      Heuristic: if column names + profile clearly describe the dataset topic, treat as inferred.

      Return EXACTLY 3 lines:
      answer: 1 or 0
      confidence: 0.0 to 1.0
      evidence: quote OR inferred-from-columns OR none
      Rules: Do NOT answer Yes/No. No extra text.

  id:
    type: binary
    prompt: |
      Task: eGMS/Dublin Core presence (heuristic).
      Field: Identifier.
      Question: Is an identifier present or inferable?
      Heuristic: presence of columns like Id/UUID/Identifier/Permalink.

      Return EXACTLY 3 lines:
      answer: 1 or 0
      confidence: 0.0 to 1.0
      evidence: quote OR inferred-from-column OR none
      Rules: Do NOT answer Yes/No. No extra text.

  pb:
    type: binary
    prompt: |
      Task: eGMS/Dublin Core presence (heuristic).
      Field: Publisher.
      Question: Is publisher present OR inferable?
      Heuristic: organisation-like values/columns (e.g., Ministry, Agency) or well-known official codes strongly tied to an organisation.

      Return EXACTLY 3 lines:
      answer: 1 or 0
      confidence: 0.0 to 1.0
      evidence: quote OR inferred-from-organisation OR none
      Rules: Do NOT answer Yes/No. No extra text.

  cv:
    type: binary
    prompt: |
      Task: eGMS/Dublin Core presence (heuristic).
      Field: Coverage (geo/temporal).
      Question: Is coverage present OR inferable?
      Heuristic: geo columns (county/municipality/EHAK/country) imply geographic coverage; date columns imply temporal coverage.

      Return EXACTLY 3 lines:
      answer: 1 or 0
      confidence: 0.0 to 1.0
      evidence: quote OR inferred-from-columns OR none
      Rules: Do NOT answer Yes/No. No extra text.

  l:
    type: binary
    prompt: |
      Task: eGMS/Dublin Core presence (heuristic).
      Field: Language.
      Question: Is language present OR inferable?
      Heuristic: if most text values appear in a single language (e.g., Estonian place names), infer language with lower confidence.

      Return EXACTLY 3 lines:
      answer: 1 or 0
      confidence: 0.0 to 1.0
      evidence: quote OR inferred-from-values OR none
      Rules: Do NOT answer Yes/No. No extra text.

  s1:
    type: binary
    prompt: |
      Task: 5-star open data check (heuristic).
      Criterion (1-star): Open license.
      Explicit: license field/name (CC BY, CC0, etc).
      Heuristic: if nothing is provided in context, return 0 (do not guess).

      Return EXACTLY 3 lines:
      answer: 1 or 0
      confidence: 0.0 to 1.0
      evidence: quote OR none
      Rules: Do NOT answer Yes/No. No extra text.

  s2:
    type: binary
    prompt: |
      Task: 5-star open data check (heuristic).
      Criterion (2-star): Structured & machine-readable.
      Heuristic: tabular columns + consistent types implies structured data.

      Return EXACTLY 3 lines:
      answer: 1 or 0
      confidence: 0.0 to 1.0
      evidence: quote OR inferred-from-tabular-structure OR none
      Rules: Do NOT answer Yes/No. No extra text.

  s3:
    type: binary
    prompt: |
      Task: 5-star open data check (heuristic).
      Criterion (3-star): Non-proprietary open format (CSV/JSON/XML).
      Use file extension in context if available.

      Return EXACTLY 3 lines:
      answer: 1 or 0
      confidence: 0.0 to 1.0
      evidence: quote OR inferred-from-format OR none
      Rules: Do NOT answer Yes/No. No extra text.

  s4:
    type: binary
    prompt: |
      Task: 5-star open data check (heuristic).
      Criterion (4-star): Uses URIs/identifiers so things can be referenced.
      Heuristic: stable identifier columns (UUID, URI-like strings, URLs).

      Return EXACTLY 3 lines:
      answer: 1 or 0
      confidence: 0.0 to 1.0
      evidence: quote OR inferred-from-pattern OR none
      Rules: Do NOT answer Yes/No. No extra text.

  s5:
    type: binary
    prompt: |
      Task: 5-star open data check (heuristic).
      Criterion (5-star): Links to other datasets (Linked Open Data).
      IMPORTANT: Do NOT output "5". Output answer only as 1 or 0.

      Return EXACTLY 3 lines:
      answer: 1 or 0
      confidence: 0.0 to 1.0
      evidence: quote OR inferred-from-linking OR none
      Rules: Do NOT answer Yes/No. No extra text.

  ncm:
    type: count_0_to_N
    prompt: |
      Task: Column documentation coverage (heuristic).
      Question: How many columns have explicit per-column metadata/definitions?
      Heuristic: if column names are self-explanatory, you may count them as partially documented (lower confidence).

      Return EXACTLY 3 lines:
      answer: integer from 0 to N
      confidence: 0.0 to 1.0
      evidence: short reason (or none)
      Rules: answer must be an integer only. No extra text.

  ncuf:
    type: count_0_to_N
    prompt: |
      Task: Column comprehensible format count (heuristic).
      Question: How many columns are in a comprehensible user-friendly format?
      Heuristic: clear names + readable values (not only cryptic codes) count as comprehensible.

      Return EXACTLY 3 lines:
      answer: integer from 0 to N
      confidence: 0.0 to 1.0
      evidence: short reason (or none)
      Rules: answer must be an integer only. No extra text.

  ns:
    type: count_0_to_N
    prompt: |
      Task: Standards applicability count (heuristic).
      Definition: ns = number of columns where a recognized standard could apply (ISO dates, ISO country codes, EHAK-like region codes, classifications).
      Heuristic: if a column looks like a code system, count it as applicable.

      Return EXACTLY 3 lines:
      answer: integer from 0 to N
      confidence: 0.0 to 1.0
      evidence: list 1-3 example columns (or none)
      Rules: answer must be an integer only. No extra text.

  nsc:
    type: count_0_to_N
    prompt: |
      Task: Standardized columns count (heuristic).
      Definition: nsc = number of columns that actually follow the associated standard consistently.
      Heuristic: if sample values match the expected standard pattern (e.g., ISO date format, numeric codes), count as standardized.

      Return EXACTLY 3 lines:
      answer: integer from 0 to N
      confidence: 0.0 to 1.0
      evidence: list 1-3 example columns (or none)
      Rules: answer must be an integer only. No extra text.
